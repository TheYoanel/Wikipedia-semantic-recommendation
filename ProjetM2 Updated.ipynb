{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e099d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nelso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\nelso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nelso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\nelso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\nelso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\nelso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "### Import all the libraries ###\n",
    "import requests \n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "#We use the wordnet to find the synonym of the word. If the synonym are the same for some words, then there is a high chance that the text is talking about this subject. The synonyms of a word are returned as a nested list of synonyms of the different senses of the input word in the given language, since these different senses are not mutual synonyms#\n",
    "nltk.download('wordnet')\n",
    "#We use the omw package with the stopswords#\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b30ec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quel est la page a consulte ?Barack Obama\n"
     ]
    }
   ],
   "source": [
    "### Create a input to ask wichpage we want to analyse###\n",
    "name = input('Quel est la page a consulte ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab2aef1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Barack Obama',\n",
       " 'Président des États-Unis au XXIe siècle',\n",
       " 'Mémorialiste américain',\n",
       " 'Mémorialiste du XXe siècle',\n",
       " 'Mémorialiste du XXIe siècle',\n",
       " 'Avocat en Illinois',\n",
       " \"Sénateur des États-Unis pour l'Illinois\",\n",
       " \"Membre du Sénat de l'État de l'Illinois\",\n",
       " 'Candidat à la présidence des États-Unis désigné par le Parti démocrate',\n",
       " 'Élection présidentielle américaine de 2008',\n",
       " 'Élection présidentielle américaine de 2012',\n",
       " 'Personnalité liée à Chicago',\n",
       " 'Politique à Chicago',\n",
       " 'Personnalité du Parti démocrate (États-Unis)',\n",
       " 'Personnalité du Parti démocrate en Illinois',\n",
       " \"Personnalité liée à la guerre d'Irak\",\n",
       " 'Personnalité politique afro-américaine',\n",
       " 'Personnalité gauchère',\n",
       " \"Victime d'une tentative de meurtre\",\n",
       " \"Étudiant de l'université Columbia\",\n",
       " 'Étudiant de la faculté de droit de Harvard',\n",
       " \"Étudiant de l'Occidental College\",\n",
       " \"Professeur à l'université de Chicago\",\n",
       " \"Docteur honoris causa de l'université Northwestern\",\n",
       " \"Docteur honoris causa de l'université de Notre-Dame-du-Lac\",\n",
       " \"Docteur honoris causa de l'université de Johannesbourg\",\n",
       " \"Personnalité de l'année selon Time Magazine\",\n",
       " 'Lauréat du prix Nobel de la paix',\n",
       " 'Lauréat américain du prix Nobel',\n",
       " \"Lauréat d'un Romy\",\n",
       " 'Membre de la Société américaine de philosophie',\n",
       " \"Membre de l'Académie américaine des arts et des sciences\",\n",
       " 'Famille Obama',\n",
       " \"Personnalité américaine née d'un parent kényan\",\n",
       " 'Naissance en août 1961',\n",
       " 'Naissance à Honolulu',\n",
       " 'Narrateur de livre audio']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################################################\n",
    "#### Scrapp the page of the given search  to give categories #####\n",
    "#################################################################\n",
    "def get_categories(name):\n",
    "    url = \"https://fr.wikipedia.org/wiki/\" + name.replace(\" \", \"_\")\n",
    "    #requete get on the main url page\n",
    "    page = requests.get(url)\n",
    "    #verification of http code\n",
    "    if page.status_code == 200:\n",
    "        #parsing the page\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        #recuperation of the categories\n",
    "        categories = soup.find_all('div', class_=\"mw-normal-catlinks\")[0]\n",
    "    else:\n",
    "        #print an error if the page is unfindable\n",
    "        print(\"Erreur lors de la requete\")\n",
    "\n",
    "    #creation of a empty list\n",
    "    liste = []\n",
    "    #recuperation of the <a> tag\n",
    "    links = categories.find_all('a')\n",
    "    #adding the content of the <a> tags to the list\n",
    "    for link in links:\n",
    "        liste.append(link.text)\n",
    "    liste.remove(\"Catégories\")\n",
    "    return(liste)\n",
    "# exemple of the execution of the function\n",
    "get_categories(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "439ee013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bédévore',\n",
       " 'Harmonide',\n",
       " 'PouX',\n",
       " 'Pautard',\n",
       " 'Vexa805',\n",
       " 'FélixFR',\n",
       " 'Philotam',\n",
       " 'Polymagou',\n",
       " 'Simans9093',\n",
       " 'Solfado',\n",
       " 'OrlodrimBot',\n",
       " 'Do not follow',\n",
       " 'Eximau',\n",
       " '2607:fa49:4103:d300:cd9:9aea:99db:c588',\n",
       " 'Malaria28',\n",
       " '37.165.59.126',\n",
       " '37.165.86.50',\n",
       " 'Jean-Christophe BENOIST',\n",
       " 'Leskheys',\n",
       " 'JLM',\n",
       " '23.91.90.210',\n",
       " 'Synoman Barris',\n",
       " '176.166.23.68',\n",
       " 'Harrieta171',\n",
       " '62.235.213.202',\n",
       " 'D952',\n",
       " '194.30.53.82',\n",
       " '66.131.96.112',\n",
       " '2a01:e0a:978:b6f0:c893:f4ac:6bc:48db',\n",
       " 'Nicolas22g',\n",
       " 'Cdigat',\n",
       " '85.26.56.197',\n",
       " 'Lomita',\n",
       " 'Susoko',\n",
       " 'Da Kong King',\n",
       " '94.109.184.95',\n",
       " 'Alexisdepris',\n",
       " '90.102.22.130',\n",
       " '81.240.80.193',\n",
       " 'Mahaef',\n",
       " '2a04:cec0:1185:c5b9:246b:8627:e5a2:a0f2',\n",
       " 'Alexcadotte',\n",
       " '2a09:1cc4:c:6d00:757a:7bd5:874b:6ff',\n",
       " 'Criric',\n",
       " 'LeFrançais2022',\n",
       " 'Cheep',\n",
       " 'Korectot',\n",
       " 'Ciaran.london',\n",
       " 'Qdesjo',\n",
       " 'Film sur Léo Major',\n",
       " 'TwoWings',\n",
       " 'Malik2Mars',\n",
       " \"Jack Rabbit Slim's\",\n",
       " 'Maxfr03',\n",
       " 'Jpor 7',\n",
       " 'Sthubertliege',\n",
       " 'WikiCleanerBot',\n",
       " 'ContributorQ',\n",
       " 'Kaftabac',\n",
       " 'Trokiodero',\n",
       " 'Jmex',\n",
       " 'Jeff13006',\n",
       " 'LeFit',\n",
       " 'Scully1181',\n",
       " 'Ræmiël',\n",
       " 'Pierrot Lunaire',\n",
       " 'Tan Khaerr',\n",
       " 'Drhimeur',\n",
       " 'Manodestina',\n",
       " 'Billinghurst',\n",
       " 'Gnurok',\n",
       " 'Contributeur2019',\n",
       " 'Farz227',\n",
       " 'Goodshort',\n",
       " 'Minniemickey20',\n",
       " 'Élisa Milan',\n",
       " 'NeoBot',\n",
       " 'Frakir',\n",
       " 'Jackycocky',\n",
       " 'Ga3lig',\n",
       " 'Chin844',\n",
       " 'Iniți',\n",
       " 'Onmycloud',\n",
       " 'Storberg',\n",
       " 'Caerula Sanguis',\n",
       " 'Etiennekd',\n",
       " 'Crazy-Hurricane',\n",
       " 'Gangodit',\n",
       " 'Vlaam',\n",
       " 'Eliogionta',\n",
       " 'Pelanch3',\n",
       " 'POUDRAS-HUSS',\n",
       " 'Fa suisse',\n",
       " 'Cardabela48',\n",
       " 'Afrik1',\n",
       " 'JarrahTree',\n",
       " 'Túrelio',\n",
       " 'Adiewibot',\n",
       " 'Ornd',\n",
       " 'Tictacbot',\n",
       " 'Charlotterch01',\n",
       " 'ProméthéeBot',\n",
       " 'Jtrec',\n",
       " 'Mbdu44',\n",
       " 'ZiziBot',\n",
       " 'Ange Gabriel',\n",
       " 'Antoine2033',\n",
       " 'HerculeBot',\n",
       " 'Mywiz',\n",
       " \"L'engoulevent\",\n",
       " 'Celette',\n",
       " 'LunettesFendues',\n",
       " 'Teddyyy',\n",
       " 'YoPaRo',\n",
       " \"Cantons-de-l'Est\",\n",
       " 'Roniee',\n",
       " '2017-CMI',\n",
       " 'HaT59',\n",
       " 'Schweiz41',\n",
       " 'Bernard Botturi',\n",
       " 'Snjor',\n",
       " 'JackBot',\n",
       " 'Mas003',\n",
       " 'Barbanegre',\n",
       " 'SenseiAC',\n",
       " 'Like tears in rain',\n",
       " 'Sofia mziouad',\n",
       " 'InternetArchiveBot',\n",
       " 'Ruyblas13',\n",
       " 'EhOuiH',\n",
       " 'Pitcairn',\n",
       " 'Mat12345678910111213',\n",
       " 'Lebelet',\n",
       " 'Hercule',\n",
       " 'Guillaume Le Conquistador',\n",
       " 'Lucio fr',\n",
       " 'Kozam',\n",
       " 'Lescandinave',\n",
       " 'Vincent Lextrait',\n",
       " 'Pierrette13',\n",
       " 'Vanished User cdJHGweI3s',\n",
       " 'Pensées de Pascal',\n",
       " 'Thierry Caro',\n",
       " 'Nomen ad hoc',\n",
       " 'Bot de pluie',\n",
       " 'Daehan',\n",
       " 'Tommy-Boy',\n",
       " 'Cholera2dog',\n",
       " 'Polmars',\n",
       " 'Stockilleur',\n",
       " 'KolbertBot',\n",
       " 'Framabot',\n",
       " 'Angelo S.',\n",
       " 'Pierrelouvier',\n",
       " 'DSisyphBot',\n",
       " 'Jules*',\n",
       " 'AviaWiki',\n",
       " 'OT38',\n",
       " 'Tobby72',\n",
       " 'Sg7438',\n",
       " 'Dale Arnett',\n",
       " 'Richelieu94',\n",
       " 'Armorino',\n",
       " 'Mro',\n",
       " 'FrançoisDufourMG',\n",
       " 'Nicolasclic',\n",
       " 'TwistGround',\n",
       " 'JCL16',\n",
       " 'Mario93',\n",
       " 'Maximus0970',\n",
       " 'Fredou JN',\n",
       " 'Maxam1392',\n",
       " 'Leparc',\n",
       " 'NoMoreHeroes',\n",
       " 'Mahdi13770105',\n",
       " 'Cyril-83',\n",
       " 'Cuny Guillaume',\n",
       " 'Yzelf',\n",
       " 'Marloen',\n",
       " 'EmDee',\n",
       " 'Alexfouch',\n",
       " 'Scientist~frwiki',\n",
       " 'Marilouw',\n",
       " 'Popee94',\n",
       " 'Laurent Roeckel',\n",
       " 'Charlouismck',\n",
       " 'FDo64',\n",
       " 'Thontep',\n",
       " 'FoxyBO2016',\n",
       " 'Albergrin007',\n",
       " 'Moeurq']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################\n",
    "#### Scrapp the page of the given search to give the user who contribute #####\n",
    "#############################################################################\n",
    "def get_user_page(name):\n",
    "    # URL but this time we replace the space by underbar, because of the url system\n",
    "    url = 'https://fr.wikipedia.org/w/index.php?title='+name.replace(\" \", \"_\")+'&action=history&offset=&limit=500'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    # Getting of all users who contribute to the page, the maximum of printable user contribution is 500 user\n",
    "    users = soup.find_all('a', {'class':'mw-userlink'})\n",
    "\n",
    "    list_user = []\n",
    "    #adding the user to the list\n",
    "    for user in users:\n",
    "        if user.text not in list_user:\n",
    "            list_user.append(user.text)\n",
    "    return(list_user)\n",
    "\n",
    "get_user_page(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6e8431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################################\n",
    "#### Scrapp the page of the user and returning the db with the 5 pages that they contribute and how much they contribute to them #####\n",
    "#####################################################################################################################################\n",
    "def sumup(name):\n",
    "    # Creating the db with panda\n",
    "    data = {'User_Name':  [],\n",
    "        'Five_most_used_Theme': [],\n",
    "        }\n",
    "    # calling the function to get the name of the contributer\n",
    "    list_user = get_user_page(name)\n",
    "    # Modifing the url to get the user contribution\n",
    "    liste_underscore = [x.replace(\" \", \"_\") for x in list_user]\n",
    "    liste_plus = [x.replace(\" \", \"+\") for x in list_user]\n",
    "    df_local = pd.DataFrame(data)\n",
    "    \n",
    "    #\n",
    "    for i in range(len(list_user)):\n",
    "        url = 'https://fr.wikipedia.org/w/index.php?title=Sp%C3%A9cial:Contributions/'+liste_underscore[i]+'&target='+liste_plus[i]+'&offset=&limit=500'\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # We count the number of iteration in the user contribution page\n",
    "        page_list = []\n",
    "        counter = {}\n",
    "        for link in soup.find_all('a', {'class': 'mw-contributions-title'}):\n",
    "            if 'Discussion' not in link.text and 'Wikipédia' not in link.text:\n",
    "                element = link.text\n",
    "                if element in counter:\n",
    "                    counter[element] += 1\n",
    "                else:\n",
    "                    counter[element] = 1\n",
    "        # We organize the number of article and select the 5 most updated page\n",
    "        sorted_counter = dict(sorted(counter.items(), key=lambda item: item[1], reverse=True))\n",
    "        top_five = dict(list(sorted_counter.items())[:5])\n",
    "        df_local = df_local.append({'User_Name': list_user[i], 'Five_most_used_Theme': top_five}, ignore_index=True)\n",
    "    return df_local\n",
    "\n",
    "df = sumup(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acbf3c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Name</th>\n",
       "      <th>Five_most_used_Theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bédévore</td>\n",
       "      <td>{'Catégorie:Chanteur du XVIIIe siècle': 3, 'Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harmonide</td>\n",
       "      <td>{'Convention internationale pour la répression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PouX</td>\n",
       "      <td>{'Vincent Bolloré': 5, 'Partmaximum': 4, 'Guy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pautard</td>\n",
       "      <td>{'Croix du Chêne de la Messe': 3, 'Tiaret': 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vexa805</td>\n",
       "      <td>{'Saison 4 de Stranger Things': 53, 'Noah Schn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_Name                               Five_most_used_Theme\n",
       "0   Bédévore  {'Catégorie:Chanteur du XVIIIe siècle': 3, 'Ca...\n",
       "1  Harmonide  {'Convention internationale pour la répression...\n",
       "2       PouX  {'Vincent Bolloré': 5, 'Partmaximum': 4, 'Guy ...\n",
       "3    Pautard  {'Croix du Chêne de la Messe': 3, 'Tiaret': 3,...\n",
       "4    Vexa805  {'Saison 4 de Stranger Things': 53, 'Noah Schn..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exemple of the database of a website, with 5 users, there top 5 contribution name and their count\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccee8c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quel est la page a consulte ?Emmanuel Macron\n"
     ]
    }
   ],
   "source": [
    "# We are doing it for another page\n",
    "name = input('Quel est la page a consulte ?')\n",
    "categories = get_categories(name)\n",
    "df2 = sumup(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91643ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Name</th>\n",
       "      <th>Five_most_used_Theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WikiCleanerBot</td>\n",
       "      <td>{'Projet:Correction syntaxique/Analyse 575': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lapin du Morvan</td>\n",
       "      <td>{'Franck Riester': 26, 'Liste d'accidents nucl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tom10tom</td>\n",
       "      <td>{'Fusillade des émeutes de Kenosha': 18, 'Emma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Groupir !</td>\n",
       "      <td>{'Utilisateur:Groupir !/Fantomas': 158, 'Le Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RobokoBot</td>\n",
       "      <td>{'Forum économique mondial': 4, 'Liste des anc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         User_Name                               Five_most_used_Theme\n",
       "0   WikiCleanerBot  {'Projet:Correction syntaxique/Analyse 575': 1...\n",
       "1  Lapin du Morvan  {'Franck Riester': 26, 'Liste d'accidents nucl...\n",
       "2         Tom10tom  {'Fusillade des émeutes de Kenosha': 18, 'Emma...\n",
       "3        Groupir !  {'Utilisateur:Groupir !/Fantomas': 158, 'Le Gr...\n",
       "4        RobokoBot  {'Forum économique mondial': 4, 'Liste des anc..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are printing the second table\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75b4552f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Name</th>\n",
       "      <th>Five_most_used_Theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bédévore</td>\n",
       "      <td>{'Catégorie:Chanteur du XVIIIe siècle': 3, 'Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pautard</td>\n",
       "      <td>{'Croix du Chêne de la Messe': 3, 'Tiaret': 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Philotam</td>\n",
       "      <td>{'Ordre de succession à l'ancien trône de Port...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polymagou</td>\n",
       "      <td>{'William Richard Tolbert': 5, 'Projet:Les san...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OrlodrimBot</td>\n",
       "      <td>{'Portail:Italie/Derniers articles créés': 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Do not follow</td>\n",
       "      <td>{'Kurt Sitte': 19, 'Harold James': 11, 'Diana ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JLM</td>\n",
       "      <td>{'François Maréchal': 22, 'Selex ES': 12, 'Dan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D952</td>\n",
       "      <td>{'Fusillade du 23 décembre 2022 à Paris': 18, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lomita</td>\n",
       "      <td>{'Saint-Vincent-de-Tyrosse': 5, 'Utilisateur:K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LeFrançais2022</td>\n",
       "      <td>{'Emmanuel Macron': 40, 'Élisabeth II': 13, 'A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cheep</td>\n",
       "      <td>{'Reconquête (parti politique)': 77, 'Présenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Korectot</td>\n",
       "      <td>{'Pelé': 21, 'Lisa Marie Presley': 19, 'Gina L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ciaran.london</td>\n",
       "      <td>{'Liz Truss': 9, 'Élections fédérales australi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jack Rabbit Slim's</td>\n",
       "      <td>{'Utilisateur:Jack Rabbit Slim's/Brouillon': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sthubertliege</td>\n",
       "      <td>{'Liste de sondages sur l'élection présidentie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WikiCleanerBot</td>\n",
       "      <td>{'Projet:Correction syntaxique/Analyse 575': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ContributorQ</td>\n",
       "      <td>{'Pierre Joris': 24, 'ILOA Les Rives de Thiers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kaftabac</td>\n",
       "      <td>{'Idéal de beauté féminin': 16, 'Avataro Senta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Jmex</td>\n",
       "      <td>{'Coupe du monde de football 2022': 60, 'Coupe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Manodestina</td>\n",
       "      <td>{'Silvio Berlusconi': 9, 'Gaël Perdriau': 8, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NeoBot</td>\n",
       "      <td>{'Projet:Aide et accueil/Twitter/Tweets': 31, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Vlaam</td>\n",
       "      <td>{'Selim Amallah': 2, 'Décès en janvier 2023': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ornd</td>\n",
       "      <td>{'Élisabeth II': 38, 'Charles III (roi du Roya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ange Gabriel</td>\n",
       "      <td>{'Sally Floyd': 8, 'René Julien Hardouin': 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HaT59</td>\n",
       "      <td>{'Mariage du diadoque Paul de Grèce et de Mari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ruyblas13</td>\n",
       "      <td>{'Achille (homonymie)': 5, 'Utilisateur:Ruybla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Pierrette13</td>\n",
       "      <td>{'American Girls' Club à Paris': 29, 'Grand te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Bot de pluie</td>\n",
       "      <td>{'Taraf TV': 1, 'Hercule Nze Souala': 1, 'À to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Jules*</td>\n",
       "      <td>{'Aide:Outils de recherche de faux-nez': 8, 'J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Mario93</td>\n",
       "      <td>{'Adele Spitzeder': 41, 'Bactron': 33, 'Edwin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Cyril-83</td>\n",
       "      <td>{'Paul de Grèce (1967)': 8, 'Linda de Suza': 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Laurent Roeckel</td>\n",
       "      <td>{'Tapura huiraatira': 83, 'Élections territori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Thontep</td>\n",
       "      <td>{'José Calvo Sotelo': 18, 'Culture d'El Argar'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             User_Name                               Five_most_used_Theme\n",
       "0             Bédévore  {'Catégorie:Chanteur du XVIIIe siècle': 3, 'Ca...\n",
       "1              Pautard  {'Croix du Chêne de la Messe': 3, 'Tiaret': 3,...\n",
       "2             Philotam  {'Ordre de succession à l'ancien trône de Port...\n",
       "3            Polymagou  {'William Richard Tolbert': 5, 'Projet:Les san...\n",
       "4          OrlodrimBot  {'Portail:Italie/Derniers articles créés': 7, ...\n",
       "5        Do not follow  {'Kurt Sitte': 19, 'Harold James': 11, 'Diana ...\n",
       "6                  JLM  {'François Maréchal': 22, 'Selex ES': 12, 'Dan...\n",
       "7                 D952  {'Fusillade du 23 décembre 2022 à Paris': 18, ...\n",
       "8               Lomita  {'Saint-Vincent-de-Tyrosse': 5, 'Utilisateur:K...\n",
       "9       LeFrançais2022  {'Emmanuel Macron': 40, 'Élisabeth II': 13, 'A...\n",
       "10               Cheep  {'Reconquête (parti politique)': 77, 'Présenta...\n",
       "11            Korectot  {'Pelé': 21, 'Lisa Marie Presley': 19, 'Gina L...\n",
       "12       Ciaran.london  {'Liz Truss': 9, 'Élections fédérales australi...\n",
       "13  Jack Rabbit Slim's  {'Utilisateur:Jack Rabbit Slim's/Brouillon': 1...\n",
       "14       Sthubertliege  {'Liste de sondages sur l'élection présidentie...\n",
       "15      WikiCleanerBot  {'Projet:Correction syntaxique/Analyse 575': 1...\n",
       "16        ContributorQ  {'Pierre Joris': 24, 'ILOA Les Rives de Thiers...\n",
       "17            Kaftabac  {'Idéal de beauté féminin': 16, 'Avataro Senta...\n",
       "18                Jmex  {'Coupe du monde de football 2022': 60, 'Coupe...\n",
       "19         Manodestina  {'Silvio Berlusconi': 9, 'Gaël Perdriau': 8, '...\n",
       "20              NeoBot  {'Projet:Aide et accueil/Twitter/Tweets': 31, ...\n",
       "21               Vlaam  {'Selim Amallah': 2, 'Décès en janvier 2023': ...\n",
       "22                Ornd  {'Élisabeth II': 38, 'Charles III (roi du Roya...\n",
       "23        Ange Gabriel  {'Sally Floyd': 8, 'René Julien Hardouin': 4, ...\n",
       "24               HaT59  {'Mariage du diadoque Paul de Grèce et de Mari...\n",
       "25           Ruyblas13  {'Achille (homonymie)': 5, 'Utilisateur:Ruybla...\n",
       "26         Pierrette13  {'American Girls' Club à Paris': 29, 'Grand te...\n",
       "27        Bot de pluie  {'Taraf TV': 1, 'Hercule Nze Souala': 1, 'À to...\n",
       "28              Jules*  {'Aide:Outils de recherche de faux-nez': 8, 'J...\n",
       "29             Mario93  {'Adele Spitzeder': 41, 'Bactron': 33, 'Edwin ...\n",
       "30            Cyril-83  {'Paul de Grèce (1967)': 8, 'Linda de Suza': 7...\n",
       "31     Laurent Roeckel  {'Tapura huiraatira': 83, 'Élections territori...\n",
       "32             Thontep  {'José Calvo Sotelo': 18, 'Culture d'El Argar'..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are taking the commun user of both table and printing the new table to show the possible in commun user and their 'passion'\n",
    "def inner_join(df1,df2):\n",
    "    return(pd.merge(df1, df2, on='User_Name', how='inner').drop(['Five_most_used_Theme_y'], axis=1).rename(columns={'Five_most_used_Theme_x': 'Five_most_used_Theme'}))\n",
    "dfmerged = inner_join(df,df2)\n",
    "dfmerged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
